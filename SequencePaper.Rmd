---
title: "SequencePaper"
author: "Elizabeth Delmelle & Eric Delmelle"
date: "2024-09-03"
output:
  html_document:
    code_folding: hide
bibliography: "references.bib"
editor_options: 
  markdown: 
    wrap: 72
header-includes:
  - \usepackage{xcolor}
---


## Sequence Analysis of Neighborhood Racial and Ethnic Changes: The Case of New York City 1980-2020

### Introduction
  Tracking and understanding neighborhood changes has been a central topic of urban studies and a fundamental concern for planning practitioners
  [@Galster2001; @Landis2016; @ChappleZuk2016]. Neighborhood change can be comprehended according to various dimensions, from housing stock or built environment changes to residents' demographic and socioeconomic composition [@Delmelle2022].  Thus, the study of neighborhood change involves analyzing multiple attribute dimensions through time for spatially situated units. Recent scholarship has progressed in the analytical strategies used to study neighborhood trajectories, introducing new methods for visualizing and mapping longitudinal pathways of change for multiple dimensions [@Delmelle2022].

  In this article, we demonstrate one such technique, sequence analysis, to explore decennial neighborhood racial and ethnic changes in New York City from 1980-2020. The United States’ demographic profile has become increasingly diverse in the past several decades, driven by immigration and growing natural birth rates of the non-White population [@Frey2022]. Analyses following the release of the 2010 decennial census showed that increasing national diversity resulted in differing neighborhood trajectories, largely contingent on the broader metropolitan context [@Terbeck2023; @Wright2014].
  
  Much of the empirical scholarship on neighborhood racial and ethnic changes has developed indices to categorize the makeup or diversity of racial and ethnic groups and then explored changes in a neighborhood’s diversity categorization over time. For example, a neighborhood might transition from ‘low diverse’ to ‘moderately diverse’ from one decade to the next [@farrell2011racial; @Wright2014]. Alternately, another set of techniques aims to describe the longitudinal sequences or trajectories that the racial and ethnic groups in a neighborhood have followed. Two methods have been used for this purpose: statistical curve fitting and sequence analysis. With curve-fitting models like growth mixture models or latent growth models, mathematical functions fit each racial and ethnic group under study that summarize the predominant trends [@Zwiers2018; @HippKim2023]. With sequence analysis, neighborhoods are first grouped into similar clusters according to their racial and ethnic makeup using an unsupervised clustering algorithm like k-means. This is done for all neighborhoods and all time stamps. Then, each neighborhood is assigned a categorical cluster over time, and finally, the sequences of these clusters are grouped using a sequence alignment technique [@Delmelle2016; @GonzalezLeonardo2023]. Both approaches aim to develop a typology of the predominant longitudinal pathways of change for multiple variables at once.

  In this article, we explore trajectories of neighborhood racial and ethnic changes in the largest and one of the most diverse cities in the United States, New York City, using longitudinal census data up to the latest 2020 decennial release. This notebook showcases a workflow that introduces sequence analysis to the study of multidimensional neighborhood changes. We begin by processing the raw longitudinal census data, then performing a k-means classification, and finally classifying sequences clusters. 
  
### Computational environment 
  The main libraries used for this analysis include `dplyr` for processing tabular census data, `sf` for mapping the resulting clusters, `cluster` for performing the `k-means` cluster analysis. We also use `factoextra` and `pheatmap` for visualing and evaluating the clustering results. Finally, to perform the sequence analysis, we use `TraMineR` [@Gabadinho2011]. This is a popular R package for performing sequence analysis for a host of social science applications, including analyses of neighborhood change. 

```{r loadlibraries, include = FALSE}
# install.packages("cluster") # Install package if you have never used it before
library(cluster) # For k-means and hierarchical cluster analysis
# install.packages("dplyr") # Install package if you have never used it before
library(dplyr) # For data management
# install.packages("sf") # Install package if you have never used it before
library(sf) #For mapping sequence clusters
# install.packages("factoextra") # Install package if you have never used it before
library(factoextra) #For visualizing k-means outputs
# install.packages("ggplot") # Install package if you have never used it before
library(ggplot2) #For data visualization
# install.packages("pheatmap") # Install package if you have never used it before
library(pheatmap) # For creating heat map to describe k-means cluster results
# install.packages("TraMineR") # Install package if you have never used it before
library(TraMineR) #For sequence clustering
# install.packages("here") # Install package if you have never used it before
library(here) #for reading in data
# install.packages("tidycensus") # Install package if you have never used it before
library(tidycensus) #for reading in census tract data (shapefile)
# install.packages("tidyverse") # Install package if you have never used it before
library(tidyverse) #for data table pivoting
```

### Data
  We use decennial census tract data to examine neighborhood racial and ethnic changes. Census tracts serve as imperfect, yet well-used neighborhood proxies. Census tract boundaries change over time, further complicating the study of population dynamics within these boundaries. There are several sources of data that have been harmonized using interpolation techniques to a consistent set of boundaries over time. We use the Longitudinal Tract Database (LTDB) which uses areal and population interpolation techniques alongside ancillary data on water cover to derive estimates (Logan et al., 2016). Analyses of the errors produced by three popular longitudinal data providers suggest that LTDB performs similarly to the dataset produced by the National Historic Geographic Information System (NHGIS) and both perform better than the Neighborhood Change Database which relies solely on areal interpolation without the inclusion of ancillary data (Logan et al., 2016). Therefore, for this type of analysis either the LTDB or NHGIS would be suitable dataset for this analysis.
  
  We obtained the fullcount decennial data from LTDB from 1980-2020 from the website (https://s4.ad.brown.edu/projects/diversity/Researcher/LTBDDload/DataList.aspx). The census variables have been interpolated to 2010 tract boundaries. Because the coding of census race and ethnicity changes over time, we opted to begin in 1980 as 1970, the earliest dataset available, did not record a count of Latino or Hispanic residents. The raw data contains all census tracts throughout the United States. Finally, we also import a shapefile of 2010 census tracts
  
### Basic conceptual intuition 
  Our analysis features two fundamental steps. The first is the *k*-means clustering of the census tracts to derive multidimensional classes of neighborhoods containing similar racial and ethnic compositions. Reibel and Regelson (2011) introduced the idea of using an unsupervised classification approach for studying neighborhood racial change as an alternative to the use of neighborhood diversity indices. The objective of the *k*-means algorithm is to group observations in such a way that maximizes the similarity of observations within groups or clusters while maximizing the dissimilarity between each cluster. In other words, the goal is to group neighborhoods so that those most similar to each other according to their racial and ethnic makeup are assigned to the same cluster and the clusters themselves are distinct from one another in terms of their makeup. With the *k*-means algorithm, the number of clusters, *k* must be determined *a priori*. To make this determination, it is customary to evaluate multiple solutions using various fit statistics in conjunction with domain and geographic knowledge of the data (Delmelle, 2015). It is also reccomended that input variables be normalized for data used in neighborhood classification research to avoid placing unequal emphasis on variables that may be on different measurement scales. However, in our case study, all of the racial and ethnic variables represent percentages of the population and so, this step is not performed in the case study. 
  Our ultimate goal is to understand the major pathways of neighborhood change and so each neighborhood will be classified five times for 1980, 1990, 2000, 2010, and 2020 to establish its longitudinal sequence. To ensure that the clusters are temporally stable, we will perform the clustering for all years at once. New neighborhood typologies may emerge over time with this approach. In that case, only tracts from the later years would be assign to the new cluster.
  Like *k*-means, sequence analysis is an unsupervised classification technique that aims to cluster similar longitudinal sequences. To determine the similarity of the sequences, a key step in this analysis is to create the dissimilarity measure. There are various approaches that can be used to determine the similarity of categorical sequences. 

```{r importdata, warning=FALSE, cache = TRUE, message=FALSE}
here ()
#csv tables for longitudinal data
census20<- read.csv("data/ltdb_std_2020_fullcount.csv")
census10<- read.csv("data/LTDB_Std_2010_fullcount.csv")
census00<- read.csv("data/LTDB_Std_2000_fullcount.csv")
census90<- read.csv("data/LTDB_Std_1990_fullcount.csv")
census80<- read.csv("data/LTDB_Std_1980_fullcount.csv")
#geometry data
#filter for NYC counties (5 boroughs)
nyc_counties <- c("Kings", "Queens", "New York", "Richmond", "Bronx")
tract <- get_decennial(geography = "tract",
                       variables = "P001001",
                       year = 2010,
                       state = "NY",
                       county = nyc_counties,
                       geometry = TRUE)
```

```{r importdata_noeval, warning=FALSE, message=FALSE,cache = TRUE, eval = FALSE}
#filter for NYC counties (5 boroughs)
nyc_counties <- c("Kings", "Queens", "New York", "Richmond", "Bronx")
tract <- get_decennial(geography = "tract",
                       variables = "P001001",
                       year = 2010,
                       state = "NY",
                       county = nyc_counties,
                       geometry = TRUE)
```


  We next calculate the share of `White`, `Black`, `Hispanic`, and `Asian` residents in each tract for each decade from the raw count using the total population as the denominator. We filter out tracts where the population is `0` and select only the relevant columns to create our data frame. We then join all columns from the five decennial data frames into one data frame called `census_all` and finally select only census tracts from the five counties that comprise New York City's five boroughs: Bronx County, Kings County (Brooklyn), New York County (Manhattan), Queens County, Richmond County (Staten Island).
  
```{r calculatepercents, warning=FALSE, message=FALSE}
census80 <- census80 %>% filter (POP80 >0)
census80$perwhite80 <- census80$NHWHT80/census80$POP80
census80$perblack80 <- census80$NHBLK80/census80$POP80
census80$perhisp80 <- census80$HISP80/census80$POP80
census80$perasian80 <- census80$ASIAN80/census80$POP80
census80<- census80 %>% select(c("TRTID10","perwhite80", "perblack80", "perhisp80", "perasian80"))

census90 <- census90 %>% filter (POP90 >0)
census90$perwhite90 <- census90$NHWHT90/census90$POP90
census90$perblack90 <- census90$NHBLK90/census90$POP90
census90$perhisp90 <- census90$HISP90/census90$POP90
census90$perasian90 <- census90$ASIAN90/census90$POP90
census90<- census90 %>% select(c("TRTID10","state","county","perwhite90", "perblack90", "perhisp90", "perasian90"))

census00 <- census00 %>% filter (POP00 >0)
census00$perwhite00 <- census00$NHWHT00/census00$POP00
census00$perblack00 <- census00$NHBLK00/census00$POP00
census00$perhisp00 <- census00$HISP00/census00$POP00
census00$perasian00 <- census00$ASIAN00/census00$POP00
census00<- census00 %>% select(c("TRTID10","perwhite00", "perblack00", "perhisp00", "perasian00"))

census10 <- census10 %>% rename("TRTID10" = "tractid")
census10$perwhite10 <- census10$nhwht10/census10$pop10
census10$perblack10 <- census10$nhblk10/census10$pop10
census10$perhisp10 <- census10$hisp10/census10$pop10
census10$perasian10 <- census10$asian10/census10$pop10
census10<- census10 %>% select(c("TRTID10","perwhite10", "perblack10", "perhisp10", "perasian10"))

census20 <- census20 %>% rename("TRTID10" = "TRTID2010")
census20$perwhite20 <- census20$nhwt20/census20$pop20
census20$perblack20 <- census20$nhblk20/census20$pop20
census20$perhisp20 <- census20$hisp20/census20$pop20
census20$perasian20 <- census20$asian20/census20$pop20
census20<- census20 %>% select(c("TRTID10","perwhite20", "perblack20", "perhisp20", "perasian20"))

#join all data frames from each decade
census_all<- census90 %>% left_join(census00) %>% left_join(., census10) %>% left_join(., census20)%>% left_join(., census80)

#Select NYC Counties. These include Bronx County, Kings County (Brooklyn), New York County (Manhattan), Queens County, Richmond County (Staten Island)

census_select <- census_all %>% filter((state == "NY" & county == "Bronx County")|
                              (state == "NY" & county == "Kings County")|
                              (state == "NY" & county == "New York County")|
                              (state == "NY" & county == "Queens County")|
                              (state == "NY" & county == "Richmond County"))

##remove NA values and state and county columns
census_nyc <- na.omit(census_select)%>% select(-state, -county)

#Select only the tractID column from the shapefile. Rename the field for ease of joining and convert to double to match the csv data.
tract<- tract %>% select("GEOID")
tract<- rename(tract, TRTID10 = GEOID)
tract$TRTID10<- as.double(tract$TRTID10)


```

  We next prepare the data for the k-means clustering. This involves pivoting the data frame so that each census tract is represented with five distinct rows, once for each decennial value. To do so, we pivot from a wide to a long format and select out just the four race and ethnicity values to be used in the clustering.
```{r kmeans}
# Convert the data frame from wide to long format
census_long <- census_nyc %>%
  pivot_longer(cols = starts_with("per"), 
               names_to = c(".value", "year"), 
               names_pattern = "per(\\w+)(\\d{2})") %>%
  mutate(year = case_when(
    year == "80" ~ 1980,
    year == "90" ~ 1990,
    year == "00" ~ 2000,
    year == "10" ~ 2010,
    year == "20" ~ 2020,
    TRUE ~ as.integer(year)
  ))


data_for_clustering <- census_long %>%
  select(white, black, hisp, asian)


```

  As explained above, the *k* means clustering procedure requires that the number of clusters, *k* be specified *a priori*. There are fit statistics that attempt to determine the optimal number of clusters, considering the similarity of observations within each cluster and the distinctiveness of the clusters from each other. However, these mathematically-derived solutions are devoid of any contextual or theoretical understanding of the problem under study. Therefore, the selection of *k* often becomes more akin to art than a science [@von2012clustering], considering the objective of the study. We begin with two common data-driven approaches that explore multiple clustering solutions for different *k* values and then examines the *within sum of squares* (WSS) and the *average silhouette score* for each solution. The WSS assesses how compact a clustering solution is, or how homogeneous the observations assigned to each cluster are, and the average silhouette score measures how well separated each cluster is from each other. Our objective is to derive a typology of neighborhoods according to their racial and ethnic makeup, for four groups: percent White, Black, Hispanic, and Asian.

```{r kmeans1}
##Now do the k-means clustering on all

data_for_clustering <- census_long %>%
  select(white, black, hisp, asian)

# Function to calculate total within-cluster sum of squares for different k
wss <- function(k) {
  kmeans(data_for_clustering, k, nstart = 10)$tot.withinss
}

# Compute and plot wss for k = 1 to k = 10
k.values <- 1:10
wss_values <- map_dbl(k.values, wss)

# Elbow method plot
plot(k.values, wss_values, type = "b", pch = 19, frame = FALSE,
     xlab = "Number of clusters K",
     ylab = "Total within-clusters sum of squares")

# Silhouette method for determining the optimal number of clusters
fviz_nbclust(data_for_clustering, kmeans, method = "silhouette")

```

  According to these plots, the optimal number of neighborhood clusters for racial makeup is three. 
  
```{r threeclusters}
# Assume the optimal number of clusters (k) is 3 from the previous steps
set.seed(123)
kmeans_result <- kmeans(data_for_clustering, centers = 3, nstart = 25)

# Add the cluster assignments to the original data
census_long$cluster <- kmeans_result$cluster


# Visualize clusters using PCA for dimensionality reduction
fviz_cluster(kmeans_result, data = data_for_clustering, geom = "point",
             choose.vars = c("white", "black"),
             ellipse.type = "norm", show.clust.cent = TRUE,
             palette = "jco", ggtheme = theme_minimal())


fviz_cluster(kmeans_result, data = data_for_clustering, geom = "point",
             choose.vars = c("asian", "hisp"),
             ellipse.type = "norm", show.clust.cent = TRUE,
             palette = "jco", ggtheme = theme_minimal())


# Silhouette Analysis
sil <- silhouette(kmeans_result$cluster, dist(data_for_clustering))
fviz_silhouette(sil)

# Average silhouette width
mean(sil[, "sil_width"])

# Cluster profiles
cluster_profiles <- census_long %>%
  group_by(cluster) %>%
  summarise(across(c(white, black, hisp, asian), mean))

print(cluster_profiles)
```



#### Sources.
